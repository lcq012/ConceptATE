{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "database = pd.read_csv('./data/limti.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cqliu/anaconda3/envs/Conate/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdb import set_trace as stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp('I')\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRON'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0].pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Handling Data: 150it [01:53,  1.32it/s]\n",
      "Handling Data: 800it [11:32,  1.15it/s]\n",
      "Handling Data: 1231it [15:52,  1.09s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "datasets = ['res14', 'res15', 'res16', 'lap14']\n",
    "types = ['dev', 'test', 'train', ]\n",
    "relation_need = [\"RelatedTo\", \"FormOf\", \"IsA\", \"PartOf\", \"HasA\",\"UsedFor\", 'Synonym', 'SimilarTo']\n",
    "relation2id = {\"RelatedTo\":0, \"FormOf\":1, \"IsA\":2, \"PartOf\":3, \"HasA\":4,\"UsedFor\":5, 'Synonym':6, 'SimilarTo':7, 'notIn':8}\n",
    "from pdb import set_trace as stop\n",
    "for dataset in datasets:\n",
    "    for type in types:\n",
    "        with open('./data/{0}/{1}/sentence.txt'.format(dataset, type), 'r') as f:\n",
    "            sent = f.readlines()\n",
    "        with open('./data/{0}/{1}/target.txt'.format(dataset, type), 'r') as f:\n",
    "            target = f.readlines()\n",
    "        Allresult = []\n",
    "        for sen, tar in tqdm(zip(sent, target), ncols=80, desc='Handling Data'):\n",
    "            singresult = []\n",
    "            newsen = sen.strip()\n",
    "            newtar = tar.strip()\n",
    "            assert len(newsen.split()) == len(newtar.split())\n",
    "            # noun_chunck = list(i for i in nlp(newsen).noun_chunks)\n",
    "            doc = nlp(newsen)\n",
    "            noun_chunck = [chunk.text.replace(chunk[0].text + \" \", \"\") if chunk[0].pos_ == \"DET\" else chunk.text for chunk in doc.noun_chunks]\n",
    "            chunck_dict_relation = {}\n",
    "            chunck_dict_id = {}\n",
    "            judge = []\n",
    "            singCom = []\n",
    "            singId = []\n",
    "            for i in noun_chunck:\n",
    "                judge.extend(str(i).split())\n",
    "            for chunck in noun_chunck:\n",
    "                chunck = str(chunck)\n",
    "                if len(chunck.split()) == 1 and nlp(chunck)[0].pos_ == 'PRON' or len(chunck) == 1 or chunck == 'people':\n",
    "                    chunck_dict_relation[chunck] = list()\n",
    "                    chunck_dict_id[chunck] = list()\n",
    "                else:\n",
    "                    chunck_dict_relation[chunck] = list(database[database['start_node']==chunck].groupby('relation').head(6)['end_node'])\n",
    "                    chunck_dict_id[chunck] = [relation2id[i] for i in list(database[database['start_node']==chunck].groupby('relation').head(6)['relation'])]\n",
    "            for word in newsen.split():\n",
    "                if word in judge:\n",
    "                    for key in chunck_dict_relation.keys():\n",
    "                        # the 存在与they中\n",
    "                        if word in key:\n",
    "                            com = chunck_dict_relation[key]\n",
    "                            comid = chunck_dict_id[key]\n",
    "                            if len(com) == 0:\n",
    "                                singCom.append(word+' '+str(key).replace(' ', '_'))\n",
    "                                singId.append('-1 '+str(relation2id['notIn']))\n",
    "                            else:\n",
    "                                singCom.append(word+' '+' '.join([str(i) for i in com]))\n",
    "                                singId.append('-1'+' '+' '.join([str(i) for i in comid]))\n",
    "                            break\n",
    "                else:\n",
    "                    singCom.append(word)\n",
    "                    singId.append('-1')\n",
    "            singresult.append(newsen)\n",
    "            singresult.append(newtar)\n",
    "            singresult.append(singCom)\n",
    "            singresult.append(singId)\n",
    "            Allresult.append(singresult)\n",
    "        with open('./newData/{0}{1}.json'.format(dataset, type), 'w') as f:\n",
    "            json.dump(Allresult, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Conate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
